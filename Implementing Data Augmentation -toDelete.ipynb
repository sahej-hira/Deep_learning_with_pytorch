{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40736d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba808678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae559b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\excel\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\excel\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\excel\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\excel\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\excel\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d697282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1baa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing instantiation:\n",
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5), \n",
    "    transforms.RandomGrayscale(0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "    \"test\": transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303497ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100      # number of samples that will be passed through the model at one time during training or testing\n",
    "train_data = datasets.CIFAR10('data', train=True,  \n",
    "download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,  \n",
    "download=True, transform=transform)\n",
    "\n",
    "# CIFAR-10:dataset used for image classification tasks,available through torchvision library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "968abe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = list(range(len(train_data)))\n",
    "#print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ea246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using a validation size of 20%, define the training and validation sampler that will be used to divide the dataset into those 2 sets:\n",
    "dev_size = 0.2\n",
    "idx = list(range(len(train_data)))\n",
    "np.random.shuffle(idx)\n",
    "split_size = int(np.floor(dev_size * len(train_data)))\n",
    "train_idx, dev_idx = idx[split_size:], idx[:split_size]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "dev_sampler = SubsetRandomSampler(dev_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3963486b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b78686",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataLoader() function to define the batches of each set of data to be used:\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,  \n",
    "batch_size=batch_size, sampler=train_sampler)\n",
    "# print(train_loader)\n",
    "dev_loader = torch.utils.data.DataLoader(train_data,  \n",
    "batch_size=batch_size, sampler=dev_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,  \n",
    "batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27a462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(20, 40, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.linear1 = nn.Linear(40 * 4 * 4, 100)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 40 * 4 * 4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.log_softmax(self.linear2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b4f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8355b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# enables training mode\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      9\u001b[0m     iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     10\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "train_losses, dev_losses, train_acc, dev_acc= [], [], [], []\n",
    "x_axis = []\n",
    "for e in range(1, epochs+1):\n",
    "    losses = 0\n",
    "    acc = 0\n",
    "    iterations = 0\n",
    "    model.train()  # enables training mode\n",
    "    for data, target in train_loader:\n",
    "        iterations += 1\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        p = torch.exp(pred)\n",
    "        top_p, top_class = p.topk(1, dim=1)\n",
    "        acc += accuracy_score(target, top_class)\n",
    "    dev_losss = 0\n",
    "    dev_accs = 0\n",
    "    iter_2 = 0\n",
    "    if e%5 == 0 or e == 1:\n",
    "        x_axis.append(e)\n",
    "        with torch.no_grad():\n",
    "            model.eval()  #evaluation mode, which disables certain layers like dropout that are only used during training.\n",
    "            for data_dev, target_dev in dev_loader:\n",
    "                iter_2 += 1\n",
    "                dev_pred = model(data_dev)\n",
    "                dev_loss = loss_function(dev_pred, target_dev)\n",
    "                dev_losss += dev_loss.item()\n",
    "                dev_p = torch.exp(dev_pred)\n",
    "                top_p, dev_top_class = dev_p.topk(1, dim=1)\n",
    "                dev_accs += accuracy_score(target_dev,  \n",
    "                dev_top_class)\n",
    "        train_losses.append(losses/iterations)\n",
    "        dev_losses.append(dev_losss/iter_2)\n",
    "        train_acc.append(acc/iterations)\n",
    "        dev_acc.append(dev_accs/iter_2)\n",
    "        print(\"Epoch: {}/{}.. \".format(e, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(losses/iterations),\n",
    "              \"Validation Loss: {:.3f}.. \".format(dev_losss/iter_2),\n",
    "              \"Training Accuracy: {:.3f}.. \".format(acc/iterations),\n",
    "              \"Validation Accuracy: {:.3f}\".format(dev_accs/iter_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05979e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, dev_losses, train_acc, dev_acc= [], [], [], []\n",
    "x_axis = []\n",
    "for e in range(1, epochs+1):\n",
    "    losses = 0\n",
    "    acc = 0\n",
    "    iterations = 0\n",
    "    model.train()  # enables training mode\n",
    "    for data, target in train_loader:\n",
    "        iterations += 1\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        p = torch.exp(pred)\n",
    "        top_p, top_class = p.topk(1, dim=1)\n",
    "        acc += accuracy_score(target, top_class)\n",
    "    dev_losss = 0\n",
    "    dev_accs = 0\n",
    "    iter_2 = 0\n",
    "    if e%5 == 0 or e == 1:\n",
    "        x_axis.append(e)\n",
    "        with torch.no_grad():\n",
    "            model.eval()  #evaluation mode, which disables certain layers like dropout that are only used during training.\n",
    "            for data_dev, target_dev in dev_loader:\n",
    "                iter_2 += 1\n",
    "                dev_pred = model(data_dev)\n",
    "                dev_loss = loss_function(dev_pred, target_dev)\n",
    "                dev_losss += dev_loss.item()\n",
    "                dev_p = torch.exp(dev_pred)\n",
    "                top_p, dev_top_class = dev_p.topk(1, dim=1)\n",
    "                dev_accs += accuracy_score(target_dev,  \n",
    "                dev_top_class)\n",
    "        train_losses.append(losses/iterations)\n",
    "        dev_losses.append(dev_losss/iter_2)\n",
    "        train_acc.append(acc/iterations)\n",
    "        dev_acc.append(dev_accs/iter_2)\n",
    "        print(\"Epoch: {}/{}.. \".format(e, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(losses/iterations),\n",
    "              \"Validation Loss: {:.3f}.. \".format(dev_losss/iter_2),\n",
    "              \"Training Accuracy: {:.3f}.. \".format(acc/iterations),\n",
    "              \"Validation Accuracy: {:.3f}\".format(dev_accs/iter_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ee58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(x_axis,train_losses, label='Training loss')\n",
    "plt.plot(x_axis, dev_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23567503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(x_axis, train_acc, label=\"Training accuracy\")\n",
    "plt.plot(x_axis, dev_acc, label=\"Validation accuracy\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2eaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking model's accuracy on the testing set\n",
    "model.eval()\n",
    "iter_3 = 0\n",
    "acc_test = 0\n",
    "for data_test, target_test in test_loader:\n",
    "    iter_3 += 1\n",
    "    test_pred = model(data_test)\n",
    "    test_pred = torch.exp(test_pred)\n",
    "    top_p, top_class_test = test_pred.topk(1, dim=1)\n",
    "    acc_test += accuracy_score(target_test, top_class_test)\n",
    "print(acc_test/iter_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304acbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82cf909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8688df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
