{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dccfbb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daea133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        Appliances  lights         T1       RH_1         T2       RH_2  \\\n",
      "0              60      30  19.890000  47.596667  19.200000  44.790000   \n",
      "1              60      30  19.890000  46.693333  19.200000  44.722500   \n",
      "2              50      30  19.890000  46.300000  19.200000  44.626667   \n",
      "3              50      40  19.890000  46.066667  19.200000  44.590000   \n",
      "4              60      40  19.890000  46.333333  19.200000  44.530000   \n",
      "...           ...     ...        ...        ...        ...        ...   \n",
      "19730         100       0  25.566667  46.560000  25.890000  42.025714   \n",
      "19731          90       0  25.500000  46.500000  25.754000  42.080000   \n",
      "19732         270      10  25.500000  46.596667  25.628571  42.768571   \n",
      "19733         420      10  25.500000  46.990000  25.414000  43.036000   \n",
      "19734         430      10  25.500000  46.600000  25.264286  42.971429   \n",
      "\n",
      "              T3       RH_3         T4       RH_4  ...         T9     RH_9  \\\n",
      "0      19.790000  44.730000  19.000000  45.566667  ...  17.033333  45.5300   \n",
      "1      19.790000  44.790000  19.000000  45.992500  ...  17.066667  45.5600   \n",
      "2      19.790000  44.933333  18.926667  45.890000  ...  17.000000  45.5000   \n",
      "3      19.790000  45.000000  18.890000  45.723333  ...  17.000000  45.4000   \n",
      "4      19.790000  45.000000  18.890000  45.530000  ...  17.000000  45.4000   \n",
      "...          ...        ...        ...        ...  ...        ...      ...   \n",
      "19730  27.200000  41.163333  24.700000  45.590000  ...  23.200000  46.7900   \n",
      "19731  27.133333  41.223333  24.700000  45.590000  ...  23.200000  46.7900   \n",
      "19732  27.050000  41.690000  24.700000  45.730000  ...  23.200000  46.7900   \n",
      "19733  26.890000  41.290000  24.700000  45.790000  ...  23.200000  46.8175   \n",
      "19734  26.823333  41.156667  24.700000  45.963333  ...  23.200000  46.8450   \n",
      "\n",
      "       T_out  Press_mm_hg     RH_out  Windspeed  Visibility  Tdewpoint  \\\n",
      "0       6.60        733.5  92.000000   7.000000   63.000000        5.3   \n",
      "1       6.48        733.6  92.000000   6.666667   59.166667        5.2   \n",
      "2       6.37        733.7  92.000000   6.333333   55.333333        5.1   \n",
      "3       6.25        733.8  92.000000   6.000000   51.500000        5.0   \n",
      "4       6.13        733.9  92.000000   5.666667   47.666667        4.9   \n",
      "...      ...          ...        ...        ...         ...        ...   \n",
      "19730  22.70        755.2  55.666667   3.333333   23.666667       13.3   \n",
      "19731  22.60        755.2  56.000000   3.500000   24.500000       13.3   \n",
      "19732  22.50        755.2  56.333333   3.666667   25.333333       13.3   \n",
      "19733  22.30        755.2  56.666667   3.833333   26.166667       13.2   \n",
      "19734  22.20        755.2  57.000000   4.000000   27.000000       13.2   \n",
      "\n",
      "             rv1        rv2  \n",
      "0      13.275433  13.275433  \n",
      "1      18.606195  18.606195  \n",
      "2      28.642668  28.642668  \n",
      "3      45.410390  45.410390  \n",
      "4      10.084097  10.084097  \n",
      "...          ...        ...  \n",
      "19730  43.096812  43.096812  \n",
      "19731  49.282940  49.282940  \n",
      "19732  29.199117  29.199117  \n",
      "19733   6.322784   6.322784  \n",
      "19734  34.118851  34.118851  \n",
      "\n",
      "[19735 rows x 28 columns]>\n",
      "(11841, 27) (11841,)\n",
      "(3947, 27) (3947,)\n",
      "(3947, 27) (3947,)\n",
      "(11841, 27) (11841,)\n",
      "(3947, 27) (3947,)\n",
      "(3947, 27) (3947,)\n"
     ]
    }
   ],
   "source": [
    "## Split the features from the targets for all three sets of data created in the previous activity. \n",
    "\n",
    "%run Splitting_a_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa71be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the DataFrames into tensors.\n",
    "\n",
    "X_train = torch.tensor(x_train.values).float()\n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "x_dev = torch.tensor(x_dev.values).float()\n",
    "y_dev = torch.tensor(y_dev.values).float()\n",
    "x_test = torch.tensor(x_test.values).float()\n",
    "y_test = torch.tensor(y_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65d23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the architecture of the network. Feel free to try different combinations of the number of layers and the number of units per layer\n",
    "model= nn.Sequential(nn.Linear(x_train.shape[1],10),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(10,7),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(7,5),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(5,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e0692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Define the loss function and the optimizer algorithm.\n",
    "# loss function\n",
    "# Adam's optimizer\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "# have only instantiated here\n",
    "\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660584e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11841, 27])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90814f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\excel\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([11841])) that is different to the input size (torch.Size([11841, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20950.25390625\n",
      "1 20718.912109375\n",
      "2 20585.583984375\n",
      "3 20466.919921875\n",
      "4 20238.59765625\n",
      "5 19919.279296875\n",
      "6 19576.419921875\n",
      "7 19149.935546875\n",
      "8 18628.634765625\n",
      "9 18004.5546875\n",
      "10 17274.11328125\n",
      "11 16441.83203125\n",
      "12 15521.458984375\n",
      "13 14547.615234375\n",
      "14 13550.521484375\n",
      "15 12575.234375\n",
      "16 11703.6220703125\n",
      "17 11046.009765625\n",
      "18 10732.306640625\n",
      "19 10862.0068359375\n",
      "20 11367.1279296875\n",
      "21 11909.9619140625\n",
      "22 12151.857421875\n",
      "23 12036.5849609375\n",
      "24 11699.783203125\n",
      "25 11309.1025390625\n",
      "26 10986.6171875\n",
      "27 10789.8857421875\n",
      "28 10721.865234375\n",
      "29 10752.283203125\n",
      "30 10838.984375\n",
      "31 10942.779296875\n",
      "32 11034.47265625\n",
      "33 11096.2646484375\n",
      "34 11120.310546875\n",
      "35 11106.501953125\n",
      "36 11060.3916015625\n",
      "37 10991.513671875\n",
      "38 10911.892578125\n",
      "39 10834.5302734375\n",
      "40 10771.6083984375\n",
      "41 10732.3681640625\n",
      "42 10720.95703125\n",
      "43 10734.8212890625\n",
      "44 10765.177734375\n",
      "45 10799.27734375\n",
      "46 10824.5009765625\n",
      "47 10832.66015625\n",
      "48 10822.388671875\n",
      "49 10798.607421875\n",
      "50 10769.6787109375\n",
      "51 10743.9169921875\n",
      "52 10726.94921875\n",
      "53 10720.6748046875\n",
      "54 10723.669921875\n",
      "55 10732.4306640625\n",
      "56 10742.8173828125\n",
      "57 10751.234375\n",
      "58 10755.3671875\n",
      "59 10754.44140625\n",
      "60 10749.11328125\n",
      "61 10741.0693359375\n",
      "62 10732.474609375\n",
      "63 10725.3798828125\n",
      "64 10721.19921875\n",
      "65 10720.380859375\n",
      "66 10722.3623046875\n",
      "67 10725.8369140625\n",
      "68 10729.2294921875\n",
      "69 10731.248046875\n",
      "70 10731.263671875\n",
      "71 10729.42578125\n",
      "72 10726.490234375\n",
      "73 10723.447265625\n",
      "74 10721.150390625\n",
      "75 10720.0615234375\n",
      "76 10720.177734375\n",
      "77 10721.123046875\n",
      "78 10722.3466796875\n",
      "79 10723.3203125\n",
      "80 10723.7001953125\n",
      "81 10723.3974609375\n",
      "82 10722.556640625\n",
      "83 10721.48046875\n",
      "84 10720.4951171875\n",
      "85 10719.8544921875\n",
      "86 10719.662109375\n",
      "87 10719.859375\n",
      "88 10720.2626953125\n",
      "89 10720.658203125\n",
      "90 10720.865234375\n",
      "91 10720.80859375\n",
      "92 10720.5185546875\n",
      "93 10720.1083984375\n",
      "94 10719.716796875\n",
      "95 10719.4501953125\n",
      "96 10719.35546875\n",
      "97 10719.40625\n",
      "98 10719.5361328125\n",
      "99 10719.66015625\n"
     ]
    }
   ],
   "source": [
    "## Use a for loop to train the network for 100 iteration steps.\n",
    "for i in range(100):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_function(y_pred,y_train)\n",
    "    print(i,loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f651ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.) tensor([94.7712], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Test your model by performing a prediction on the first instance of the testing set and comparing it to the ground truth.\n",
    "\n",
    "pred = model(x_test[0])\n",
    "print(y_test[0], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d59740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63718467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
