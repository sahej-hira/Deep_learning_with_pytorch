{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9e0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f5c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path='checkpoint.pth'):\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    # Extract the input size and other hyperparameters\n",
    "    input_size = checkpoint['input_size']\n",
    "    learning_rate = checkpoint['learning_rate']\n",
    "    \n",
    "    # Recreate the model\n",
    "    model = Classifier(input_size=input_size)\n",
    "    \n",
    "    # Load the model state\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    # Recreate the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    return model, optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87a1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from final_model import Classifier # # import the text file in which info is saved \n",
    "\n",
    "# Define the model and load the checkpoint\n",
    "model, _ = load_model(checkpoint_path='checkpoint.pth')\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define a sample input tensor for tracing\n",
    "sample_input = torch.tensor([[0.0606, 0.5000, 0.3333, 0.4828, 0.4000, 0.4000, 0.4000, \n",
    "                              0.4000, 0.4000, 0.4000, 0.1651, 0.0869, 0.0980, 0.1825, \n",
    "                              0.1054, 0.2807, 0.0016, 0.0000, 0.0033, 0.0027, 0.0031, \n",
    "                              0.0021]]).float()\n",
    "\n",
    "# Create a TorchScript model using tracing\n",
    "traced_model = torch.jit.trace(model, sample_input)\n",
    "# standalone and do not require Python to run.\n",
    "# can be loaded and run on different platforms, including mobile devices\n",
    "\n",
    "\n",
    "# Save the traced model\n",
    "traced_model.save('traced_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e9c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# Load the traced model\n",
    "traced_model = torch.jit.load('traced_model.pt')\n",
    "\n",
    "# Define the input tensor\n",
    "input_tensor = torch.tensor([[0.0606, 0.5000, 0.3333, 0.4828, 0.4000, 0.4000, 0.4000, \n",
    "                              0.4000, 0.4000, 0.4000, 0.1651, 0.0869, 0.0980, 0.1825, \n",
    "                              0.1054, 0.2807, 0.0016, 0.0000, 0.0033, 0.0027, 0.0031, \n",
    "                              0.0021]]).float()\n",
    "\n",
    "# Perform prediction with the traced model\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    output = traced_model(input_tensor)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278f311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
