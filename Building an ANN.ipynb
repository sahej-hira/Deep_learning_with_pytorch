{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f98c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the following libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93885a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160138</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163220</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173637</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.272928</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.109363</td>\n",
       "      <td>0.283685</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179863</td>\n",
       "      <td>0.099633</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  EDUCATION  MARRIAGE       AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   0.010101   0.333333  0.333333  0.051724    0.4    0.4    0.1    0.1   \n",
       "1   0.111111   0.333333  0.666667  0.086207    0.1    0.4    0.2    0.2   \n",
       "2   0.080808   0.333333  0.666667  0.224138    0.2    0.2    0.2    0.2   \n",
       "3   0.040404   0.333333  0.333333  0.275862    0.2    0.2    0.2    0.2   \n",
       "4   0.040404   0.333333  0.333333  0.620690    0.1    0.2    0.1    0.2   \n",
       "\n",
       "   PAY_5  PAY_6  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0    0.0    0.0  ...   0.160138   0.080648   0.260979  0.000000  0.000409   \n",
       "1    0.2    0.4  ...   0.163220   0.084074   0.263485  0.000000  0.000594   \n",
       "2    0.2    0.2  ...   0.173637   0.095470   0.272928  0.001738  0.000891   \n",
       "3    0.2    0.2  ...   0.186809   0.109363   0.283685  0.002290  0.001199   \n",
       "4    0.2    0.2  ...   0.179863   0.099633   0.275681  0.002290  0.021779   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0  0.000000  0.000000  0.000000  0.000000                           1  \n",
       "1  0.001116  0.001610  0.000000  0.003783                           1  \n",
       "2  0.001116  0.001610  0.002345  0.009458                           0  \n",
       "3  0.001339  0.001771  0.002506  0.001892                           0  \n",
       "4  0.011160  0.014493  0.001615  0.001284                           0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the previously prepared dataset.\n",
    "\n",
    "data = pd.read_csv(\"dccc_prepared.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc6a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the features from the target.\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data[\"default.payment.next.month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01bc7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using scikit-learn's train_test_split function, split the dataset into training, validation, and testing sets. Use a 60/20/20% split ratio. Set random_state as 0.\n",
    "\n",
    "x_new, x_test, y_new, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x_new, y_new, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# X_new, X_test, y_new, y_test = train_test_split(X, y,  test_size=0.2, random_state=0)\n",
    "# dev_per = X_test.shape[0]/X_new.shape[0]\n",
    "# X_train, X_dev, y_train, y_dev = train_test_split(X_new,  y_new, test_size=dev_per, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed3a3d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19200, 22) (19200,)\n",
      "(4800, 22) (4800,)\n",
      "(6000, 22) (6000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_dev.shape, y_dev.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2611bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the validation and testing sets to tensors, considering that the features matrices should be of type float, while the target matrices should not. Leave the training sets unconverted for the moment as they will undergo further transformations.\n",
    "\n",
    "# X_train = torch.tensor(x_train.values).float()\n",
    "# y_train = torch.tensor(y_train.values).float()\n",
    "\n",
    "x_dev = torch.tensor(x_dev.values).float()\n",
    "y_dev = torch.tensor(y_dev.values).float()\n",
    "\n",
    "x_test = torch.tensor(x_test.values).float()\n",
    "y_test = torch.tensor(y_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05118bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of builtin_function_or_method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_dev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_dev\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_test\u001b[38;5;241m.\u001b[39mvalues)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "y_dev = torch.tensor(y_dev.values)\n",
    "y_test = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82a71994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# additional:\n",
    "print(type(x_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94dad118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional:\n",
    "# converting training_set back to a dataframe\n",
    "# shouldn't have converted it to a tensor in the first place\n",
    "\n",
    "#x_train = pd.DataFrame(x_train.numpy())\n",
    "#y_train = pd.DataFrame(y_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e1ef839",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a custom module class defining the layers of the network. Include a forward \n",
    "## function that specifies the activation functions that will be applied to the output \n",
    "## of each layer. Use ReLU for all layers, except for the output, where you should use \n",
    "## log_softmax.\n",
    "\n",
    "class Classifier(nn.Module):  # custom module\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.hidden_1 = nn.Linear(input_size, 10)\n",
    "        self.hidden_2 = nn.Linear(10, 10)\n",
    "        self.hidden_3 = nn.Linear(10, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.hidden_1(x))\n",
    "        z = F.relu(self.hidden_2(z))\n",
    "        z = F.relu(self.hidden_3(z))\n",
    "        out = F.log_softmax(self.output(z), dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e77e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cae9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8380d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b819e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3e039c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define all the variables required for the training of the model. Set the number of \n",
    "## epochs to 50 and the batch size to 128. Use a learning rate of 0.001.\n",
    "\n",
    "model = Classifier(x_train.shape[1])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5209d8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     32\u001b[0m     log_dev \u001b[38;5;241m=\u001b[39m model(x_dev)\n\u001b[1;32m---> 33\u001b[0m     dev_loss \u001b[38;5;241m=\u001b[39m criterion(log_dev, y_dev)\n\u001b[0;32m     34\u001b[0m     ps_dev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_dev)\n\u001b[0;32m     35\u001b[0m     top_p, top_class_dev \u001b[38;5;241m=\u001b[39m ps_dev\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnll_loss(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2729\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2728\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mnll_loss_nd(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "## Train the network using the training sets data. Use the validation sets to measure \n",
    "## performance. To do so, save the loss and the accuracy for both the training and \n",
    "## validation sets in each epoch.\n",
    "\n",
    "## The training process may take several minutes, depending on your resources. \n",
    "## Adding print statements is a good practice to see the progress of the training \n",
    "## process.\n",
    "\n",
    "train_losses, dev_losses, train_acc, dev_acc= [], [], [], []\n",
    "for e in range(epochs):\n",
    "    X_, y_ = shuffle(x_train, y_train)\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    iterations = 0\n",
    "    for i in range(0, len(X_), batch_size):\n",
    "        iterations += 1\n",
    "        b = i + batch_size\n",
    "        X_batch = torch.tensor(X_.iloc[i:b,:].values).float()\n",
    "        y_batch = torch.tensor(y_.iloc[i:b].values).long()\n",
    "        log_ps = model(X_batch)\n",
    "        loss = criterion(log_ps, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        running_acc += accuracy_score(y_batch, top_class)\n",
    "        dev_loss = 0\n",
    "        acc = 0\n",
    "        with torch.no_grad():\n",
    "            log_dev = model(x_dev)\n",
    "            dev_loss = criterion(log_dev, y_dev)\n",
    "            ps_dev = torch.exp(log_dev)\n",
    "            top_p, top_class_dev = ps_dev.topk(1, dim=1)\n",
    "            acc = accuracy_score(y_dev, top_class_dev)\n",
    "        train_losses.append(running_loss/iterations)\n",
    "        dev_losses.append(dev_loss)\n",
    "        train_acc.append(running_acc/iterations)\n",
    "        dev_acc.append(acc)\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "            \"Training Loss: {:.3f}.. \".format(running_loss/iterations),\n",
    "            \"Validation Loss: {:.3f}.. \".format(dev_loss),\n",
    "            \"Training Accuracy: {:.3f}.. \".format(running_acc/ \n",
    "                                                  iterations),\n",
    "            \"Validation Accuracy: {:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the loss of both sets.\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(dev_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Plot the accuracy of both sets.\n",
    "\n",
    "plt.plot(train_acc, label=\"Training accuracy\")\n",
    "plt.plot(dev_acc, label=\"Validation accuracy\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52418f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
